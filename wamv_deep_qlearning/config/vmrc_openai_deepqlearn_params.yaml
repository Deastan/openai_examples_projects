wamv: #namespace

    #qlearn parameters
    
    alpha: 0.01 # Learning Rate
    alpha_decay: 0.01
    gamma: 1.0 # future rewards value 0 none 1 a lot
    epsilon: 1.0 # exploration, 0 none 1 a lot
    epsilon_decay: 0.995 # how we reduse the exploration
    epsilon_min: 0.01 # minimum value that epsilon can have
    batch_size: 64 # maximum size of the batches sampled from memory
    episodes_training: 40
    episodes_running: 10
    n_win_ticks: 80 # If the mean of rewards is bigger than this and have passed min_episodes, the task is considered finished
    min_episodes: 10
    #max_env_steps: None
    monitor: True
    quiet: False
    

    # Boat Realated parameters


    propeller_high_speed: 1.0 # High Propeller Speed             
    propeller_low_speed: 0.2 # Low Propeller Speed
    max_angular_speed: 1.0 # Maximum Base Turn Angular speed
    n_observations: 9
    n_actions: 4 # Number of actions used by algorithm and task
    
    work_space: # 3D cube in which Drone is allowed to move
      x_max: 30.0
      x_min: -1.0
      y_max: 5.0
      y_min: -5.0
    
    desired_point:
      x: 30.0
      y: 0.0
      z: 1.0
    
    desired_point_epsilon: 0.5
    max_distance_from_des_point: 30.0 # Maximum distance regitered in observations, has to be bigger than the largest distance of the workspace.
    number_decimals_precision_obs: 1
    
    
    done_reward: 1000.0 # reward
    closer_to_point_reward: 100.0 # reward