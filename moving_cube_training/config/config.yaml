moving_cube: #namespace

    #qlearn parameters
    
    alpha: 0.10 # Learning Rate
    alpha_decay: 0.01
    gamma: 1.0 # future rewards value 0 none 1 a lot
    epsilon: 1.0 # exploration, 0 none 1 a lot
    epsilon_decay: 0.98 # how we reduse the exploration
    epsilon_min: 0.01 # minimum value that epsilon can have
    batch_size: 64 # maximum size of the batches sampled from memory
    episodes_training: 300
    episodes_running: 10
    n_win_ticks: 30 # If the mean of rewards is bigger than this and have passed min_episodes, the task is considered finished
    min_episodes: 10
    #max_env_steps: None
    monitor: True
    quiet: False
    

    # Cube Realated parameters


    roll_speed_fixed_value: 50.0 # High Propeller Speed             
    roll_speed_increment_value: 10.0 # Low Propeller Speed

    
    max_pitch_angle: 0.3
    max_yaw_angle: 0.3
    
    max_distance: 10.0 # Maximum Base Turn Angular speed
    max_y_linear_speed: 100

    init_roll_vel: 10
    
    init_cube_pose: # 3D cube in which Drone is allowed to move
      x: 0.0
      y: 0.0
      z: 0.0
    
    n_observations: 6
    n_actions: 3 # Number of actions used by algorithm and task
    
    move_distance_reward_weight: 100.0 # reward
    y_linear_speed_reward_weight: 100.0
    y_axis_angle_reward_weight: 100.0
    roll_reward_weight: 120
    end_episode_points: -10.0